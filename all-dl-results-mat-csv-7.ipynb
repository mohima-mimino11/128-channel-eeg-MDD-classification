{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13509254,"sourceType":"datasetVersion","datasetId":5468552}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T17:47:22.504554Z","iopub.execute_input":"2025-11-23T17:47:22.504790Z","iopub.status.idle":"2025-11-23T17:47:24.331389Z","shell.execute_reply.started":"2025-11-23T17:47:22.504767Z","shell.execute_reply":"2025-11-23T17:47:24.330598Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010030rest 20160324 1054..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020025rest 20150713 1519..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010013rest 20150703 1333..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020016rest 20150701 1040..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020015_rest 20150630 1527.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010022restnew 20150724 14.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020027rest 20150713 1049..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010008_rest 20150619 1653.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010011rest 20150625 1516..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020029rest 20150715 1316..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020023restnew 20150709 10.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010012rest 20150626 1026..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030020_rest 20151230 1416.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010018rest 20150716 1237..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010002rest 20150416 1017..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020010rest 20150625 1224..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010016rest 20150710 1220..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020008rest 20150624 1711..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010024rest 20150814 1504..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030004_rest 20151026 1930.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020020rest 20150703 1754..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020018rest 20150702 1651..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010010rest 20150624 1447..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030002rest_new 20151022 1.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010033rest 20160331 1239..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020019rest 20150703 1036..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010005rest 20150507 0907..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030007_rest 20151103 2032.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030017_rest 20151208 1329.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030018_rest 20151208 1443.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020013rest 20150629 1607..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010026rest 20160311 1421..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030006_rest 20151103 1725.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010023rest 20150729 1929..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020021rest 20150707 1720..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020026_rest 20150714 1413.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030019_rest 20151230 1314.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030005rest 20151026 2103..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010015rest 20150709 1456..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030009_rest 20151105 1113.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010006rest 20150528 0928..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030003_rest 20151022 1155.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010004rest 20150427 1335..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020022rest 20150707 1452..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030021rest 20160105 1141..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010036_rest 20160408 1418.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010034rest 20160407 0938..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010028rest 20160317 1538..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030014rest 20151117 1441..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010019rest 20150716 1440..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020014_rest 20150630 1023.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030017erp 20151208 1351-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010002erp 20150416 1131-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010011erp 20150625 1545-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010024erp 20150814 1523-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010018erp 20150716 1310-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010010erp 20150624 1508-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020025_erp 20150713 1541-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010030erp 20160324 0915-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030021erp 20160105 1204-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020020_erp 20150703 1810-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020027_erp 20150713 1116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030020_erp 20151230 1443-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010015erp 20150709 1534-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010013erp 20150703 1353-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010023erp 20150729 1955-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030009erp 20151105 1207-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010025erp 20160311 1225-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010021erp 20150805 1818-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020016_erp 20150701 1054-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010034erp 20160407 0959-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020019_erp 20150703 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030005erp 20151026 2116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020013_erp 20150629 1622-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020029_erp 20150715 1401-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010019erp 20150716 1544-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020026_erp 20150714 1428-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010033erp 20160331 1307-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010005erp 20150507 0938-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010006erp 20150528 1007-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030019_erp 20151230 1331-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030006 20151103 1801-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010004erp 20141219 1602-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020010_erp 20150625 1244-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030007 20151103 2129-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030014erp 20151117 1419-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030002erp_new 20151022 14-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020015_erp 20150630 1547-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020021_erp 20150707 1751-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010012erp 20150626 1059-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010028erp 20160317 1554-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020022_erp 20150707 1515-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020018_erp 20150702 1721-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020023_erpnew 20150709 110-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010026erp 20160311 1441-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010016erp 20150710 1329-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010008_erp(n) 20150619 1709-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020008_erp 20150624 1740-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010036erp 20160408 1452-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010022erp 20150724 1457-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020014_erp 20150630 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/18.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/20.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/07.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/24.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/11.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/17.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/16.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/19.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/26.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/28.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/13.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/23.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/14.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/22.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/06.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/05.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/12.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/09.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/04.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/01.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/03.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/15.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/all_audio_features.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/10.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/08.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/25.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/29.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/21.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/27.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/02.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Setup, load & preprocessing, save splits**","metadata":{}},{"cell_type":"code","source":"# CELL 1: Setup + Load + Preprocess + Save splits\nimport os, re, math, json, warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import IncrementalPCA\n\n# CONFIG\nDATA_DIR    = '/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2'\nOUTPUT_DIR  = '/kaggle/working/dl_results'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nSAMPLE_FRAC      = 1.0        # set 0.1 for quick tests\nUSE_IPCA         = True\nIPCA_COMPONENTS  = 128\nIPCA_BATCH       = 5000\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# GPU memory growth (optional)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor g in gpus:\n    try:\n        tf.config.experimental.set_memory_growth(g, True)\n    except Exception:\n        pass\n\n# helpers\ndef detect_eeg_columns(columns):\n    regex = re.compile(r'^(?:EEG[_\\-\\s]?|E[_\\-\\s]?)(0*?)(\\d{1,3})$', flags=re.I)\n    found = {}\n    for c in columns:\n        m = regex.match(c.strip())\n        if m:\n            num = int(m.group(2))\n            if 1 <= num <= 128:\n                found[num] = c\n    if found:\n        return [found[i] for i in sorted(found.keys())]\n    # fallback\n    return [c for c in columns if re.match(r'^(E|EEG)\\d+', c, flags=re.I)]\n\ndef to_binary_label_series(s):\n    s = s.dropna()\n    if s.empty: return None\n    s_num = pd.to_numeric(s, errors='coerce')\n    if s_num.notna().all():\n        uniq = set(np.unique(s_num))\n        if uniq.issubset({0,1}): return s_num.astype(int)\n        if uniq.issubset({1,2}): return s_num.map({1:0,2:1}).astype(int)\n        med = float(s_num.median()); return (s_num > med).astype(int)\n    s_str = s.astype(str)\n    unique_vals = s_str.unique()\n    if len(unique_vals) == 1: return s_str.map({unique_vals[0]:0}).astype(int)\n    if len(unique_vals) == 2:\n        le = LabelEncoder().fit(unique_vals)\n        return pd.Series(le.transform(s_str), index=s_str.index).astype(int)\n    mode_val = s_str.mode().iat[0]; return (s_str != mode_val).astype(int)\n\n# 1) Read CSVs\ncsvs = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.csv')])\nif len(csvs)==0:\n    raise RuntimeError(\"No CSV files in DATA_DIR\")\nprint(\"Found\", len(csvs), \"CSV files.\")\n\nparts = []\nfor fn in csvs:\n    path = os.path.join(DATA_DIR, fn)\n    df = pd.read_csv(path, engine='python')\n    if SAMPLE_FRAC is not None and 0 < SAMPLE_FRAC < 1.0:\n        df = df.sample(frac=SAMPLE_FRAC, random_state=SEED)\n    df['__source_file'] = os.path.splitext(fn)[0]\n    parts.append(df)\ncombined = pd.concat(parts, ignore_index=True)\nprint(\"Combined shape:\", combined.shape)\n\n# 2) label detection (prefer epoch, label, condition)\nlabel_cols_try = ['epoch','label','condition','cond','target']\nlabel_series = None\nfor c in label_cols_try:\n    if c in combined.columns:\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Using\", c, \"as labels.\")\n            break\nif label_series is None:\n    # fallback search\n    for c in combined.columns:\n        if c.startswith('__'): continue\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Fallback using\", c, \"as labels.\")\n            break\nif label_series is None:\n    raise RuntimeError(\"No suitable label column found. Ensure 'epoch'/'label' exists.\")\n\nprint(\"Label distribution:\", label_series.value_counts().to_dict())\nif label_series.nunique() <= 1:\n    print(\"Detected single class after mapping â€” abort and inspect label columns.\")\n    raise RuntimeError(\"Single-class dataset. Fix labels.\")\n\ncombined['__label'] = label_series.astype(int)\n\n# 3) Detect EEG columns & form feature matrix\neeg_cols = detect_eeg_columns(combined.columns)\nif not eeg_cols:\n    raise RuntimeError(\"No EEG columns detected; check column names.\")\nprint(\"Detected EEG columns:\", len(eeg_cols))\n# drop known metadata columns\ndrop_cols = {'time','condition','label','epoch','__source_file','__label'}\nfeature_cols = [c for c in eeg_cols if c not in drop_cols]\nif len(feature_cols) == 0:\n    raise RuntimeError(\"No feature columns after filtering.\")\nX_full = combined[feature_cols].to_numpy(dtype=np.float32)\ny = combined['__label'].to_numpy(dtype=np.int32)\nprint(\"X_full shape:\", X_full.shape, \"y shape:\", y.shape)\n\n# impute NaNs\nif np.isnan(X_full).any():\n    col_means = np.nanmean(X_full, axis=0)\n    inds = np.where(np.isnan(X_full)); X_full[inds] = np.take(col_means, inds[1])\n    print(\"Imputed NaNs.\")\n\n# 4) Optional IncrementalPCA\nif USE_IPCA and IPCA_COMPONENTS is not None and 0 < IPCA_COMPONENTS < X_full.shape[1]:\n    print(\"Running IncrementalPCA...\")\n    ipca = IncrementalPCA(n_components=IPCA_COMPONENTS)\n    n = X_full.shape[0]; bs = IPCA_BATCH\n    for i in range(0, n, bs):\n        ipca.partial_fit(X_full[i:i+bs])\n    X_reduced = np.empty((n, IPCA_COMPONENTS), dtype=np.float32)\n    for i in range(0, n, bs):\n        X_reduced[i:i+bs] = ipca.transform(X_full[i:i+bs]).astype(np.float32)\n    X = X_reduced\nelse:\n    X = X_full\nprint(\"Post-PCA shape:\", X.shape)\n\n# 5) scale and split (save splits for model cells)\nscaler = StandardScaler()\nX = scaler.fit_transform(X).astype(np.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n# persist splits so model cells can load them\nnp.savez_compressed(os.path.join(OUTPUT_DIR, 'data_split.npz'),\n                    X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\nprint(\"Saved data_split.npz to\", OUTPUT_DIR)\n# create empty models_results.json if not exists\nres_path = os.path.join(OUTPUT_DIR, 'models_results.json')\nif not os.path.exists(res_path):\n    with open(res_path,'w') as f: json.dump([], f)\nprint(\"Cell 1 done.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Utility functions**","metadata":{}},{"cell_type":"code","source":"# CELL 2: Utility functions for model cells (run once)\nimport os, json, numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n\nOUTPUT_DIR = '/kaggle/working/dl_results'\ndef load_data_splits():\n    p = os.path.join(OUTPUT_DIR, 'data_split.npz')\n    d = np.load(p)\n    return d['X_train'], d['X_test'], d['y_train'], d['y_test']\n\ndef save_model_result(res):\n    \"\"\"Append JSON-serializable result dict to models_results.json\"\"\"\n    p = os.path.join(OUTPUT_DIR, 'models_results.json')\n    lst = []\n    if os.path.exists(p):\n        with open(p,'r') as f:\n            try:\n                lst = json.load(f)\n            except Exception:\n                lst = []\n    lst.append(res)\n    with open(p,'w') as f:\n        json.dump(lst, f)\n\ndef make_result_dict(name, model, X_test, y_test, history=None):\n    # predict probabilities where possible\n    try:\n        probs = model.predict(X_test, verbose=0).ravel()\n    except Exception:\n        # if model expects 3D or 4D, let caller reshape X_test appropriately before calling make_result_dict\n        probs = model.predict(X_test, verbose=0).ravel()\n    preds = (probs >= 0.5).astype(int)\n    acc = float(accuracy_score(y_test, preds))\n    try:\n        roc_auc = float(roc_auc_score(y_test, probs))\n    except Exception:\n        roc_auc = None\n    rep = classification_report(y_test, preds)\n    cm = confusion_matrix(y_test, preds).tolist()\n    try:\n        fpr,tpr,_ = roc_curve(y_test, probs)\n        fpr = fpr.tolist(); tpr = tpr.tolist()\n    except Exception:\n        fpr,tpr = [], []\n    hist_dict = history.history if history is not None else {}\n    # convert numpy types in hist to lists\n    clean_hist = {k: (list(np.array(v).astype(float)) if hasattr(v,'__iter__') else v) for k,v in hist_dict.items()}\n    res = {\n        'name': name,\n        'accuracy': acc,\n        'roc_auc': roc_auc,\n        'class_report': rep,\n        'conf_mat': cm,\n        'fpr': fpr,\n        'tpr': tpr,\n        'history': clean_hist\n    }\n    return res\n\nprint(\"Cell 2 loaded utilities.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T18:47:50.934757Z","iopub.execute_input":"2025-11-22T18:47:50.935564Z","iopub.status.idle":"2025-11-22T18:47:50.945377Z","shell.execute_reply.started":"2025-11-22T18:47:50.935539Z","shell.execute_reply":"2025-11-22T18:47:50.944547Z"}},"outputs":[{"name":"stdout","text":"Cell 2 loaded utilities.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **GAN**","metadata":{}},{"cell_type":"markdown","source":"# **GAN-Fixed**","metadata":{}},{"cell_type":"code","source":"# ================================\n# CELL 3 â€” Vanilla GAN (1000 epochs) - Kaggle-optimized\n# Saves BEST + LAST weights for Generator & Discriminator\n# ================================\nimport os, time, gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n\n# ---------------- Config ----------------\nOUTPUT_DIR = \"/kaggle/working/dl_results\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nLATENT_DIM = 100\nEPOCHS_GAN = 1000\nBATCH = 64\nCLASSIFIER_EPOCHS = 50\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# ---------------- Load data ----------------\nX_train, X_test, y_train, y_test = load_data_splits()\nX = X_train.astype(np.float32)\nFEATURES = X.shape[1]\nN_train = X.shape[0]\n\nprint(f\"[GAN] features={FEATURES} | n_train={N_train}\")\n\n# ---------------- Build models ----------------\ndef build_generator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(256, input_dim=LATENT_DIM),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(FEATURES, activation='tanh')\n    ])\n\ndef build_discriminator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(512, input_shape=(FEATURES,)),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n\ngenerator = build_generator()\ndiscriminator = build_discriminator()\n\nopt_d = tf.keras.optimizers.Adam(0.0002, 0.5)\nopt_g = tf.keras.optimizers.Adam(0.0002, 0.5)\n\n# ---------------- GAN model ----------------\nz = tf.keras.Input(shape=(LATENT_DIM,))\nfake_x = generator(z)\ndiscriminator.trainable = False\ngan = tf.keras.Model(z, discriminator(fake_x))\ngan.compile(optimizer=opt_g, loss=\"binary_crossentropy\")\ndiscriminator.compile(optimizer=opt_d, loss=\"binary_crossentropy\")\n\n# ---------------- tf.data pipeline ----------------\nAUTOTUNE = tf.data.AUTOTUNE\nds = tf.data.Dataset.from_tensor_slices(X).shuffle(10000).repeat().batch(BATCH).prefetch(AUTOTUNE)\nds_iter = iter(ds)\n\nreal_label = tf.ones((BATCH,1), tf.float32)\nfake_label = tf.zeros((BATCH,1), tf.float32)\n\n# ---------------- Training step ----------------\n@tf.function\ndef train_step(real_batch):\n    # --- Train Discriminator on real & fake ---\n    noise = tf.random.normal((BATCH, LATENT_DIM))\n    fake_batch = generator(noise, training=True)\n\n    with tf.GradientTape() as t1:\n        pred_real = discriminator(real_batch, training=True)\n        loss_real = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, pred_real))\n\n    grads_real = t1.gradient(loss_real, discriminator.trainable_variables)\n    opt_d.apply_gradients(zip(grads_real, discriminator.trainable_variables))\n\n    with tf.GradientTape() as t2:\n        pred_fake = discriminator(fake_batch, training=True)\n        loss_fake = tf.reduce_mean(tf.keras.losses.binary_crossentropy(fake_label, pred_fake))\n\n    grads_fake = t2.gradient(loss_fake, discriminator.trainable_variables)\n    opt_d.apply_gradients(zip(grads_fake, discriminator.trainable_variables))\n\n    # --- Train Generator ---\n    noise2 = tf.random.normal((BATCH, LATENT_DIM))\n    with tf.GradientTape() as t3:\n        gen_out = generator(noise2, training=True)\n        disc_out = discriminator(gen_out, training=False)\n        loss_g = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, disc_out))\n\n    grads_g = t3.gradient(loss_g, generator.trainable_variables)\n    opt_g.apply_gradients(zip(grads_g, generator.trainable_variables))\n\n    return (loss_real + loss_fake) * 0.5, loss_g\n\n# ---------------- Adversarial Training ----------------\nprint(\"[GAN] Training started...\")\nd_losses, g_losses = [], []\nbest_g_loss = 999999.0\ngen_best_path = os.path.join(OUTPUT_DIR, \"generator_best_main.weights.h5\")\n\nstart = time.time()\nfor epoch in range(EPOCHS_GAN):\n    real_batch = next(ds_iter)\n    d_loss_val, g_loss_val = train_step(real_batch)\n\n    d_losses.append(float(d_loss_val))\n    g_losses.append(float(g_loss_val))\n\n    # Save BEST generator\n    if epoch == 0 or float(g_loss_val) < best_g_loss:\n        best_g_loss = float(g_loss_val)\n        generator.save_weights(gen_best_path)\n\n    if epoch % 50 == 0:\n        print(f\"[{epoch}/{EPOCHS_GAN}] D={d_losses[-1]:.4f} | G={g_losses[-1]:.4f}\")\n\nprint(f\"[GAN] Finished in {time.time()-start:.1f}s\")\n\nprint(f\"BEST generator loss = {best_g_loss:.5f}\")\nprint(f\"Saved BEST generator weights â†’ {gen_best_path}\")\n\n# ---------------- Classifier Training ----------------\ndef mixed_batch_generator(X_real, y_real, batch):\n    n = X_real.shape[0]\n    half = batch // 2\n    while True:\n        idx = np.random.randint(0, n, half)\n        real_x = X_real[idx]\n        real_y = y_real[idx].reshape(-1,1).astype(np.float32)\n\n        noise = np.random.normal(0,1,(half,LATENT_DIM)).astype(np.float32)\n        gen_x = generator.predict(noise, verbose=0)\n        gen_y = np.zeros((half,1), np.float32)\n\n        Xb = np.vstack([real_x, gen_x])\n        yb = np.vstack([real_y, gen_y])\n        perm = np.random.permutation(len(Xb))\n\n        yield Xb[perm], yb[perm]\n\ntrain_gen = mixed_batch_generator(X, y_train, BATCH)\nsteps_per_epoch = max(10, N_train // BATCH)\n\ndisc_best_path = os.path.join(OUTPUT_DIR, \"disc_classifier_best_main.weights.h5\")\n\ncheckpoint = ModelCheckpoint(disc_best_path, monitor=\"val_loss\",\n                             save_best_only=True, save_weights_only=True)\nearly = EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True)\n\ndiscriminator.trainable = True\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002,0.5),\n                      loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nhistory = discriminator.fit(\n    train_gen,\n    steps_per_epoch=steps_per_epoch,\n    epochs=CLASSIFIER_EPOCHS,\n    validation_data=(X_test, y_test.reshape(-1,1)),\n    callbacks=[checkpoint, early],\n    verbose=1\n)\n\n# ---------------- Evaluation ----------------\ny_prob = discriminator.predict(X_test).ravel()\ny_pred = (y_prob >= 0.5).astype(int)\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))\n\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nauc_val = roc_auc_score(y_test, y_prob)\n\nplt.figure(figsize=(5,5))\nplt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\nplt.plot([0,1],[0,1],'k--')\nplt.legend()\nplt.title(\"GAN Discriminator ROC\")\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_discriminator_roc.png\"), dpi=100)\nplt.close()\n\nplt.figure(figsize=(6,3))\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history[\"val_accuracy\"])\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_disc_acc.png\"), dpi=100)\nplt.close()\n\nplt.figure(figsize=(6,3))\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_disc_loss.png\"), dpi=100)\nplt.close()\n\n# ---------------- Save JSON ----------------\nres = make_result_dict(\"Vanilla_GAN_best_gen_and_disc\", discriminator, X_test, y_test, history)\nres.update({\n    \"best_generator_weights\": os.path.basename(gen_best_path),\n    \"best_discriminator_weights\": os.path.basename(disc_best_path),\n})\nsave_model_result(res)\n\n# ---------------- SAVE LAST EPOCH WEIGHTS ----------------\ngen_last_path = os.path.join(OUTPUT_DIR, \"generator_last_main.weights.h5\")\ndisc_last_path = os.path.join(OUTPUT_DIR, \"discriminator_last_main.weights.h5\")\n\ngenerator.save_weights(gen_last_path)\ndiscriminator.save_weights(disc_last_path)\n\nprint(f\"[SAVED] Last generator weights â†’ {gen_last_path}\")\nprint(f\"[SAVED] Last discriminator weights â†’ {disc_last_path}\")\n\n# ---------------- Cleanup ----------------\nK.clear_session()\ngc.collect()\n\nprint(\"ðŸ”¥ CELL 3 DONE â€” Best + Last weights saved for Generator & Discriminator.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T18:47:55.667074Z","iopub.execute_input":"2025-11-22T18:47:55.667781Z","iopub.status.idle":"2025-11-22T18:48:16.972269Z","shell.execute_reply.started":"2025-11-22T18:47:55.667754Z","shell.execute_reply":"2025-11-22T18:48:16.971268Z"}},"outputs":[{"name":"stdout","text":"[GAN] features=128 | n_train=3089910\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1763837289.140756      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1763837289.141483      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"[GAN] Training started...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1379056478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS_GAN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mreal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0md_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0md_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/__autograph_generated_fileenbywndd.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(real_batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mgrads_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mpred_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_48/1379056478.py\", line 90, in train_step  *\n        opt_d.apply_gradients(zip(grads_real, discriminator.trainable_variables))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 382, in apply_gradients  **\n        grads, trainable_variables = zip(*grads_and_vars)\n\n    ValueError: not enough values to unpack (expected 2, got 0)\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_48/1379056478.py\", line 90, in train_step  *\n        opt_d.apply_gradients(zip(grads_real, discriminator.trainable_variables))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 382, in apply_gradients  **\n        grads, trainable_variables = zip(*grads_and_vars)\n\n    ValueError: not enough values to unpack (expected 2, got 0)\n","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"# ================================\n# CELL 3 â€” Vanilla GAN (1000 epochs) - Kaggle-optimized\n# Saves BEST + LAST weights for Generator & Discriminator\n# ================================\nimport os, time, gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n\n# ---------- Config ----------\nOUTPUT_DIR = \"/kaggle/working/dl_results\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nLATENT_DIM = 100\nEPOCHS_GAN = 1000\nBATCH = 64\nCLASSIFIER_EPOCHS = 50\nSEED = 42\nnp.random.seed(SEED); tf.random.set_seed(SEED)\n\n# ---------- Load pre-saved splits (Cell 1/2 required) ----------\nX_train, X_test, y_train, y_test = load_data_splits()\nX = X_train.astype(np.float32)\nFEATURES = X.shape[1]\nN_train = X.shape[0]\nprint(f\"[GAN] features={FEATURES} | n_train={N_train}\")\n\n# ---------- Build Generator & Discriminator (unchanged architecture) ----------\ndef build_generator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(256, input_dim=LATENT_DIM),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(FEATURES, activation='tanh')\n    ], name=\"generator\")\n\ndef build_discriminator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(512, input_shape=(FEATURES,)),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ], name=\"discriminator\")\n\ngenerator = build_generator()\ndiscriminator = build_discriminator()\n\nopt_d = tf.keras.optimizers.Adam(0.0002, 0.5)\nopt_g = tf.keras.optimizers.Adam(0.0002, 0.5)\n\n# ---------- Build GAN wrapper (for generator training via BCE) ----------\nz = tf.keras.Input(shape=(LATENT_DIM,))\nfake_x = generator(z)\n# freeze discriminator when building gan model (standard)\ndiscriminator.trainable = False\ngan = tf.keras.Model(z, discriminator(fake_x))\ngan.compile(optimizer=opt_g, loss=\"binary_crossentropy\")\n# compile discriminator standalone (we'll use custom training steps)\ndiscriminator.compile(optimizer=opt_d, loss=\"binary_crossentropy\")\n\n# ---------- tf.data pipeline for streaming real batches ----------\nAUTOTUNE = tf.data.AUTOTUNE\nds = tf.data.Dataset.from_tensor_slices(X).shuffle(10000, seed=SEED).repeat().batch(BATCH).prefetch(AUTOTUNE)\nds_iter = iter(ds)\n\nreal_label = tf.ones((BATCH,1), tf.float32)\nfake_label = tf.zeros((BATCH,1), tf.float32)\n\n# ---------- Ensure trainable flags are correct before custom training ----------\ndiscriminator.trainable = True\ngenerator.trainable = True\n\n# ---------- Robust @tf.function train step (handles None grads) ----------\n@tf.function\ndef train_step(real_batch):\n    # Train Discriminator on real examples\n    noise = tf.random.normal((BATCH, LATENT_DIM))\n    fake_batch = generator(noise, training=True)\n\n    with tf.GradientTape() as t1:\n        pred_real = discriminator(real_batch, training=True)\n        loss_real = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, pred_real))\n    grads_real = t1.gradient(loss_real, discriminator.trainable_variables)\n    grads_and_vars = [(g, v) for g, v in zip(grads_real, discriminator.trainable_variables) if g is not None]\n    if grads_and_vars:\n        opt_d.apply_gradients(grads_and_vars)\n\n    # Train Discriminator on fake examples\n    with tf.GradientTape() as t2:\n        pred_fake = discriminator(fake_batch, training=True)\n        loss_fake = tf.reduce_mean(tf.keras.losses.binary_crossentropy(fake_label, pred_fake))\n    grads_fake = t2.gradient(loss_fake, discriminator.trainable_variables)\n    grads_and_vars = [(g, v) for g, v in zip(grads_fake, discriminator.trainable_variables) if g is not None]\n    if grads_and_vars:\n        opt_d.apply_gradients(grads_and_vars)\n\n    # Train Generator (via GAN objective: make discriminator predict real)\n    noise2 = tf.random.normal((BATCH, LATENT_DIM))\n    with tf.GradientTape() as t3:\n        gen_out = generator(noise2, training=True)\n        # evaluate discriminator in inference mode\n        disc_out = discriminator(gen_out, training=False)\n        loss_g = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, disc_out))\n    grads_g = t3.gradient(loss_g, generator.trainable_variables)\n    grads_and_vars = [(g, v) for g, v in zip(grads_g, generator.trainable_variables) if g is not None]\n    if grads_and_vars:\n        opt_g.apply_gradients(grads_and_vars)\n\n    return (loss_real + loss_fake) * 0.5, loss_g\n\n# ---------- Adversarial training loop (memory-safe streaming) ----------\nprint(\"[GAN] Adversarial training started...\")\nd_losses, g_losses = [], []\nbest_g_loss = np.inf\ngen_best_path = os.path.join(OUTPUT_DIR, \"generator_best_main.weights.h5\")\n\nstart_time = time.time()\nfor epoch in range(EPOCHS_GAN):\n    real_batch = next(ds_iter)  # streaming minibatch\n    d_loss_val, g_loss_val = train_step(real_batch)\n\n    d_losses.append(float(d_loss_val))\n    g_losses.append(float(g_loss_val))\n\n    # Save BEST generator weights (tiny) when g_loss improves\n    if float(g_loss_val) < best_g_loss:\n        best_g_loss = float(g_loss_val)\n        try:\n            generator.save_weights(gen_best_path)\n        except Exception as e:\n            print(\"Warning saving best generator weights:\", e)\n\n    if epoch % 50 == 0:\n        print(f\"[Epoch {epoch}/{EPOCHS_GAN}] D={d_losses[-1]:.4f} | G={g_losses[-1]:.4f}\")\n\nprint(f\"[GAN] Adversarial training finished in {(time.time()-start_time):.1f}s\")\nprint(f\"[GAN] Best generator loss: {best_g_loss:.6f} â†’ saved to {gen_best_path}\")\n\n# ---------- Train discriminator as classifier using streamed synthetic (no large saves) ----------\ndef mixed_batch_generator(X_real, y_real, batch):\n    n = X_real.shape[0]\n    half = batch // 2\n    while True:\n        idx = np.random.randint(0, n, half)\n        real_x = X_real[idx]\n        real_y = y_real[idx].reshape(-1,1).astype(np.float32)\n\n        noise = np.random.normal(0,1,(half, LATENT_DIM)).astype(np.float32)\n        gen_x = generator.predict(noise, verbose=0)\n        gen_y = np.zeros((half,1), dtype=np.float32)\n\n        Xb = np.vstack([real_x, gen_x])\n        yb = np.vstack([real_y, gen_y])\n        perm = np.random.permutation(len(Xb))\n\n        yield Xb[perm], yb[perm]\n\ntrain_gen = mixed_batch_generator(X, y_train, BATCH)\nsteps_per_epoch = max(10, N_train // BATCH)\n\ndisc_best_path = os.path.join(OUTPUT_DIR, \"disc_classifier_best_main.weights.h5\")\n# ModelCheckpoint requires .weights.h5 when save_weights_only=True\ncheckpoint = ModelCheckpoint(disc_best_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True, verbose=0)\nearly = EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True)\n\n# Re-compile discriminator for classifier fine-tuning\ndiscriminator.trainable = True\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n                      loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\n# Use compact validation set (X_test) for quick val checks\nval_data = (X_test.astype(np.float32), y_test.reshape(-1,1).astype(np.float32))\n\nprint(\"[Classifier] Fine-tuning discriminator as classifier (streamed synthetic)...\")\nhistory = discriminator.fit(\n    train_gen,\n    steps_per_epoch=steps_per_epoch,\n    epochs=CLASSIFIER_EPOCHS,\n    validation_data=val_data,\n    callbacks=[checkpoint, early],\n    verbose=1\n)\n\n# ---------- Save LAST weights (tiny) ----------\ngen_last_path = os.path.join(OUTPUT_DIR, \"generator_last_main.weights.h5\")\ndisc_last_path = os.path.join(OUTPUT_DIR, \"discriminator_last_main.weights.h5\")\ntry:\n    generator.save_weights(gen_last_path)\n    discriminator.save_weights(disc_last_path)\nexcept Exception as e:\n    print(\"Warning saving last weights:\", e)\n\n# ---------- Evaluate on X_test and save small PNGs & JSON ----------\ny_prob = discriminator.predict(X_test.astype(np.float32), verbose=0).ravel()\ny_pred = (y_prob >= 0.5).astype(int)\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))\n\n# ROC + AUC\ntry:\n    auc_val = float(roc_auc_score(y_test, y_prob))\nexcept Exception:\n    auc_val = None\n\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nplt.figure(figsize=(5,5))\nplt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\" if auc_val is not None else \"ROC\")\nplt.plot([0,1],[0,1],'k--', alpha=0.3)\nplt.title(\"GAN Discriminator ROC\")\nplt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_discriminator_roc.png\"), dpi=100)\nplt.close()\n\n# Train/Val curves (tiny)\nplt.figure(figsize=(6,3))\nif 'accuracy' in history.history:\n    plt.plot(history.history.get('accuracy', []), label='train_acc')\n    plt.plot(history.history.get('val_accuracy', []), label='val_acc')\n    plt.legend(); plt.title(\"Train/Val Accuracy\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR,\"gan_disc_acc.png\"), dpi=100)\n    plt.close()\n\nplt.figure(figsize=(6,3))\nplt.plot(history.history.get('loss', []), label='train_loss')\nplt.plot(history.history.get('val_loss', []), label='val_loss')\nplt.legend(); plt.title(\"Train/Val Loss\")\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_disc_loss.png\"), dpi=100)\nplt.close()\n\n# Save small JSON summary via helper\nres = make_result_dict(\"Vanilla_GAN_best_gen_and_disc\", discriminator, X_test, y_test, history)\nres.update({\n    \"best_generator_weights\": os.path.basename(gen_best_path),\n    \"best_discriminator_weights\": os.path.basename(disc_best_path) if os.path.exists(disc_best_path) else None,\n    \"last_generator_weights\": os.path.basename(gen_last_path),\n    \"last_discriminator_weights\": os.path.basename(disc_last_path),\n    \"gan_epochs\": int(EPOCHS_GAN)\n})\nsave_model_result(res)\nprint(\"[JSON] GAN result appended to models_results.json\")\n\n# ---------- Cleanup ----------\nK.clear_session()\ndel train_gen, generator, discriminator, gan, ds_iter\ngc.collect()\n\nprint(\"CELL 3 DONE â€” Best + Last weights saved for Generator & Discriminator.\")\nprint(\"Files in:\", OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T18:53:45.353950Z","iopub.execute_input":"2025-11-22T18:53:45.354267Z","execution_failed":"2025-11-23T06:33:04.615Z"}},"outputs":[{"name":"stdout","text":"[GAN] features=128 | n_train=3089910\n[GAN] Adversarial training started...\n[Epoch 0/1000] D=0.7015 | G=0.7190\n[Epoch 50/1000] D=0.5996 | G=1.1754\n[Epoch 100/1000] D=0.5972 | G=0.9374\n[Epoch 150/1000] D=0.5452 | G=0.8271\n[Epoch 200/1000] D=0.7037 | G=0.8502\n[Epoch 250/1000] D=0.5765 | G=1.0324\n[Epoch 300/1000] D=0.7250 | G=0.9082\n[Epoch 350/1000] D=0.5633 | G=1.0090\n[Epoch 400/1000] D=0.7418 | G=0.8414\n[Epoch 450/1000] D=0.7056 | G=1.1800\n[Epoch 500/1000] D=0.6641 | G=0.8385\n[Epoch 550/1000] D=0.6552 | G=0.8614\n[Epoch 600/1000] D=0.6244 | G=1.0132\n[Epoch 650/1000] D=0.6242 | G=0.9307\n[Epoch 700/1000] D=0.6283 | G=0.8464\n[Epoch 750/1000] D=0.6960 | G=0.7569\n[Epoch 800/1000] D=0.6430 | G=0.8459\n[Epoch 850/1000] D=0.7464 | G=0.7527\n[Epoch 900/1000] D=0.7422 | G=0.7379\n[Epoch 950/1000] D=0.7057 | G=0.8253\n[GAN] Adversarial training finished in 9.9s\n[GAN] Best generator loss: 0.502903 â†’ saved to /kaggle/working/dl_results/generator_best_main.weights.h5\n[Classifier] Fine-tuning discriminator as classifier (streamed synthetic)...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1763837653.680750     114 service.cc:148] XLA service 0x79fb24013700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1763837653.681592     114 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1763837653.681611     114 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1763837653.751627     114 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1763837654.046785     114 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3066s\u001b[0m 63ms/step - accuracy: 0.7800 - loss: 0.3409 - val_accuracy: 0.6469 - val_loss: 0.5980\nEpoch 2/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2807s\u001b[0m 58ms/step - accuracy: 0.8178 - loss: 0.3043 - val_accuracy: 0.6775 - val_loss: 0.5630\nEpoch 3/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2823s\u001b[0m 58ms/step - accuracy: 0.8288 - loss: 0.2919 - val_accuracy: 0.7003 - val_loss: 0.5385\nEpoch 4/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2819s\u001b[0m 58ms/step - accuracy: 0.8358 - loss: 0.2845 - val_accuracy: 0.7114 - val_loss: 0.5238\nEpoch 5/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2802s\u001b[0m 58ms/step - accuracy: 0.8408 - loss: 0.2785 - val_accuracy: 0.7201 - val_loss: 0.5129\nEpoch 6/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2818s\u001b[0m 58ms/step - accuracy: 0.8439 - loss: 0.2752 - val_accuracy: 0.7304 - val_loss: 0.5004\nEpoch 7/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2820s\u001b[0m 58ms/step - accuracy: 0.8468 - loss: 0.2715 - val_accuracy: 0.7398 - val_loss: 0.4907\nEpoch 8/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2803s\u001b[0m 58ms/step - accuracy: 0.8489 - loss: 0.2691 - val_accuracy: 0.7400 - val_loss: 0.4865\nEpoch 9/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2837s\u001b[0m 59ms/step - accuracy: 0.8510 - loss: 0.2663 - val_accuracy: 0.7469 - val_loss: 0.4814\nEpoch 10/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2863s\u001b[0m 59ms/step - accuracy: 0.8521 - loss: 0.2649 - val_accuracy: 0.7499 - val_loss: 0.4763\nEpoch 11/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2882s\u001b[0m 60ms/step - accuracy: 0.8535 - loss: 0.2630 - val_accuracy: 0.7459 - val_loss: 0.4758\nEpoch 12/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2819s\u001b[0m 58ms/step - accuracy: 0.8549 - loss: 0.2614 - val_accuracy: 0.7597 - val_loss: 0.4672\nEpoch 13/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2861s\u001b[0m 59ms/step - accuracy: 0.8554 - loss: 0.2602 - val_accuracy: 0.7543 - val_loss: 0.4708\nEpoch 14/50\n\u001b[1m48279/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2825s\u001b[0m 59ms/step - accuracy: 0.8566 - loss: 0.2588 - val_accuracy: 0.7611 - val_loss: 0.4613\nEpoch 15/50\n\u001b[1m19571/48279\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m27:05\u001b[0m 57ms/step - accuracy: 0.8569 - loss: 0.2582","output_type":"stream"}],"execution_count":null}]}