{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13509254,"sourceType":"datasetVersion","datasetId":5468552}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:49:31.770797Z","iopub.execute_input":"2025-12-04T07:49:31.771049Z","iopub.status.idle":"2025-12-04T07:49:34.006044Z","shell.execute_reply.started":"2025-12-04T07:49:31.771020Z","shell.execute_reply":"2025-12-04T07:49:34.005285Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010030rest 20160324 1054..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020025rest 20150713 1519..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010013rest 20150703 1333..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020016rest 20150701 1040..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020015_rest 20150630 1527.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010022restnew 20150724 14.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020027rest 20150713 1049..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010008_rest 20150619 1653.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010011rest 20150625 1516..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020029rest 20150715 1316..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020023restnew 20150709 10.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010012rest 20150626 1026..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030020_rest 20151230 1416.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010018rest 20150716 1237..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010002rest 20150416 1017..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020010rest 20150625 1224..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010016rest 20150710 1220..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020008rest 20150624 1711..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010024rest 20150814 1504..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030004_rest 20151026 1930.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020020rest 20150703 1754..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020018rest 20150702 1651..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010010rest 20150624 1447..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030002rest_new 20151022 1.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010033rest 20160331 1239..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020019rest 20150703 1036..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010005rest 20150507 0907..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030007_rest 20151103 2032.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030017_rest 20151208 1329.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030018_rest 20151208 1443.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020013rest 20150629 1607..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010026rest 20160311 1421..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030006_rest 20151103 1725.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010023rest 20150729 1929..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020021rest 20150707 1720..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020026_rest 20150714 1413.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030019_rest 20151230 1314.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030005rest 20151026 2103..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010015rest 20150709 1456..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030009_rest 20151105 1113.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010006rest 20150528 0928..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030003_rest 20151022 1155.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010004rest 20150427 1335..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020022rest 20150707 1452..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030021rest 20160105 1141..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010036_rest 20160408 1418.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010034rest 20160407 0938..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010028rest 20160317 1538..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030014rest 20151117 1441..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010019rest 20150716 1440..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020014_rest 20150630 1023.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030017erp 20151208 1351-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010002erp 20150416 1131-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010011erp 20150625 1545-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010024erp 20150814 1523-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010018erp 20150716 1310-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010010erp 20150624 1508-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020025_erp 20150713 1541-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010030erp 20160324 0915-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030021erp 20160105 1204-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020020_erp 20150703 1810-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020027_erp 20150713 1116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030020_erp 20151230 1443-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010015erp 20150709 1534-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010013erp 20150703 1353-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010023erp 20150729 1955-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030009erp 20151105 1207-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010025erp 20160311 1225-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010021erp 20150805 1818-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020016_erp 20150701 1054-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010034erp 20160407 0959-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020019_erp 20150703 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030005erp 20151026 2116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020013_erp 20150629 1622-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020029_erp 20150715 1401-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010019erp 20150716 1544-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020026_erp 20150714 1428-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010033erp 20160331 1307-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010005erp 20150507 0938-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010006erp 20150528 1007-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030019_erp 20151230 1331-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030006 20151103 1801-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010004erp 20141219 1602-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020010_erp 20150625 1244-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030007 20151103 2129-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030014erp 20151117 1419-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030002erp_new 20151022 14-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020015_erp 20150630 1547-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020021_erp 20150707 1751-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010012erp 20150626 1059-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010028erp 20160317 1554-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020022_erp 20150707 1515-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020018_erp 20150702 1721-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020023_erpnew 20150709 110-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010026erp 20160311 1441-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010016erp 20150710 1329-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010008_erp(n) 20150619 1709-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020008_erp 20150624 1740-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010036erp 20160408 1452-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010022erp 20150724 1457-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020014_erp 20150630 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/18.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/20.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/07.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/24.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/11.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/17.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/16.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/19.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/26.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/28.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/13.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/23.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/14.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/22.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/06.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/05.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/12.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/09.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/04.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/01.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/03.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/15.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/all_audio_features.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/10.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/08.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/25.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/29.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/21.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/27.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/02.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Setup, load & preprocessing, save splits**","metadata":{}},{"cell_type":"code","source":"# CELL 1: Setup + Load + Preprocess + Save splits\nimport os, re, math, json, warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import IncrementalPCA\n\n# CONFIG\nDATA_DIR    = '/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2'\nOUTPUT_DIR  = '/kaggle/working/dl-results-3'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nSAMPLE_FRAC      = 1.0        # set 0.1 for quick tests\nUSE_IPCA         = True\nIPCA_COMPONENTS  = 128\nIPCA_BATCH       = 5000\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# GPU memory growth (optional)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor g in gpus:\n    try:\n        tf.config.experimental.set_memory_growth(g, True)\n    except Exception:\n        pass\n\n# helpers\ndef detect_eeg_columns(columns):\n    regex = re.compile(r'^(?:EEG[_\\-\\s]?|E[_\\-\\s]?)(0*?)(\\d{1,3})$', flags=re.I)\n    found = {}\n    for c in columns:\n        m = regex.match(c.strip())\n        if m:\n            num = int(m.group(2))\n            if 1 <= num <= 128:\n                found[num] = c\n    if found:\n        return [found[i] for i in sorted(found.keys())]\n    # fallback\n    return [c for c in columns if re.match(r'^(E|EEG)\\d+', c, flags=re.I)]\n\ndef to_binary_label_series(s):\n    s = s.dropna()\n    if s.empty: return None\n    s_num = pd.to_numeric(s, errors='coerce')\n    if s_num.notna().all():\n        uniq = set(np.unique(s_num))\n        if uniq.issubset({0,1}): return s_num.astype(int)\n        if uniq.issubset({1,2}): return s_num.map({1:0,2:1}).astype(int)\n        med = float(s_num.median()); return (s_num > med).astype(int)\n    s_str = s.astype(str)\n    unique_vals = s_str.unique()\n    if len(unique_vals) == 1: return s_str.map({unique_vals[0]:0}).astype(int)\n    if len(unique_vals) == 2:\n        le = LabelEncoder().fit(unique_vals)\n        return pd.Series(le.transform(s_str), index=s_str.index).astype(int)\n    mode_val = s_str.mode().iat[0]; return (s_str != mode_val).astype(int)\n\n# 1) Read CSVs\ncsvs = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.csv')])\nif len(csvs)==0:\n    raise RuntimeError(\"No CSV files in DATA_DIR\")\nprint(\"Found\", len(csvs), \"CSV files.\")\n\nparts = []\nfor fn in csvs:\n    path = os.path.join(DATA_DIR, fn)\n    df = pd.read_csv(path, engine='python')\n    if SAMPLE_FRAC is not None and 0 < SAMPLE_FRAC < 1.0:\n        df = df.sample(frac=SAMPLE_FRAC, random_state=SEED)\n    df['__source_file'] = os.path.splitext(fn)[0]\n    parts.append(df)\ncombined = pd.concat(parts, ignore_index=True)\nprint(\"Combined shape:\", combined.shape)\n\n# 2) label detection (prefer epoch, label, condition)\nlabel_cols_try = ['epoch','label','condition','cond','target']\nlabel_series = None\nfor c in label_cols_try:\n    if c in combined.columns:\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Using\", c, \"as labels.\")\n            break\nif label_series is None:\n    # fallback search\n    for c in combined.columns:\n        if c.startswith('__'): continue\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Fallback using\", c, \"as labels.\")\n            break\nif label_series is None:\n    raise RuntimeError(\"No suitable label column found. Ensure 'epoch'/'label' exists.\")\n\nprint(\"Label distribution:\", label_series.value_counts().to_dict())\nif label_series.nunique() <= 1:\n    print(\"Detected single class after mapping — abort and inspect label columns.\")\n    raise RuntimeError(\"Single-class dataset. Fix labels.\")\n\ncombined['__label'] = label_series.astype(int)\n\n# 3) Detect EEG columns & form feature matrix\neeg_cols = detect_eeg_columns(combined.columns)\nif not eeg_cols:\n    raise RuntimeError(\"No EEG columns detected; check column names.\")\nprint(\"Detected EEG columns:\", len(eeg_cols))\n# drop known metadata columns\ndrop_cols = {'time','condition','label','epoch','__source_file','__label'}\nfeature_cols = [c for c in eeg_cols if c not in drop_cols]\nif len(feature_cols) == 0:\n    raise RuntimeError(\"No feature columns after filtering.\")\nX_full = combined[feature_cols].to_numpy(dtype=np.float32)\ny = combined['__label'].to_numpy(dtype=np.int32)\nprint(\"X_full shape:\", X_full.shape, \"y shape:\", y.shape)\n\n# impute NaNs\nif np.isnan(X_full).any():\n    col_means = np.nanmean(X_full, axis=0)\n    inds = np.where(np.isnan(X_full)); X_full[inds] = np.take(col_means, inds[1])\n    print(\"Imputed NaNs.\")\n\n# 4) Optional IncrementalPCA\nif USE_IPCA and IPCA_COMPONENTS is not None and 0 < IPCA_COMPONENTS < X_full.shape[1]:\n    print(\"Running IncrementalPCA...\")\n    ipca = IncrementalPCA(n_components=IPCA_COMPONENTS)\n    n = X_full.shape[0]; bs = IPCA_BATCH\n    for i in range(0, n, bs):\n        ipca.partial_fit(X_full[i:i+bs])\n    X_reduced = np.empty((n, IPCA_COMPONENTS), dtype=np.float32)\n    for i in range(0, n, bs):\n        X_reduced[i:i+bs] = ipca.transform(X_full[i:i+bs]).astype(np.float32)\n    X = X_reduced\nelse:\n    X = X_full\nprint(\"Post-PCA shape:\", X.shape)\n\n# 5) scale and split (save splits for model cells)\nscaler = StandardScaler()\nX = scaler.fit_transform(X).astype(np.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n# persist splits so model cells can load them\nnp.savez_compressed(os.path.join(OUTPUT_DIR, 'data_split.npz'),\n                    X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\nprint(\"Saved data_split.npz to\", OUTPUT_DIR)\n# create empty models_results.json if not exists\nres_path = os.path.join(OUTPUT_DIR, 'models_results.json')\nif not os.path.exists(res_path):\n    with open(res_path,'w') as f: json.dump([], f)\nprint(\"Cell 1 done.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T14:53:59.846602Z","iopub.execute_input":"2025-12-03T14:53:59.847095Z","iopub.status.idle":"2025-12-03T15:03:53.874498Z","shell.execute_reply.started":"2025-12-03T14:53:59.847068Z","shell.execute_reply":"2025-12-03T15:03:53.873411Z"}},"outputs":[{"name":"stdout","text":"Found 51 CSV files.\nCombined shape: (3862388, 133)\nUsing epoch as labels.\nLabel distribution: {0: 1932951, 1: 1929437}\nDetected EEG columns: 128\nX_full shape: (3862388, 128) y shape: (3862388,)\nPost-PCA shape: (3862388, 128)\nSaved data_split.npz to /kaggle/working/dl-results-3\nCell 1 done.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **Utility functions**","metadata":{}},{"cell_type":"code","source":"# CELL 2: Utility functions for model cells (run once)\nimport os, json, numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n\nOUTPUT_DIR = '/kaggle/working/dl-results-3'\ndef load_data_splits():\n    p = os.path.join(OUTPUT_DIR, 'data_split.npz')\n    d = np.load(p)\n    return d['X_train'], d['X_test'], d['y_train'], d['y_test']\n\ndef save_model_result(res):\n    \"\"\"Append JSON-serializable result dict to models_results.json\"\"\"\n    p = os.path.join(OUTPUT_DIR, 'models_results.json')\n    lst = []\n    if os.path.exists(p):\n        with open(p,'r') as f:\n            try:\n                lst = json.load(f)\n            except Exception:\n                lst = []\n    lst.append(res)\n    with open(p,'w') as f:\n        json.dump(lst, f)\n\ndef make_result_dict(name, model, X_test, y_test, history=None):\n    # predict probabilities where possible\n    try:\n        probs = model.predict(X_test, verbose=0).ravel()\n    except Exception:\n        # if model expects 3D or 4D, let caller reshape X_test appropriately before calling make_result_dict\n        probs = model.predict(X_test, verbose=0).ravel()\n    preds = (probs >= 0.5).astype(int)\n    acc = float(accuracy_score(y_test, preds))\n    try:\n        roc_auc = float(roc_auc_score(y_test, probs))\n    except Exception:\n        roc_auc = None\n    rep = classification_report(y_test, preds)\n    cm = confusion_matrix(y_test, preds).tolist()\n    try:\n        fpr,tpr,_ = roc_curve(y_test, probs)\n        fpr = fpr.tolist(); tpr = tpr.tolist()\n    except Exception:\n        fpr,tpr = [], []\n    hist_dict = history.history if history is not None else {}\n    # convert numpy types in hist to lists\n    clean_hist = {k: (list(np.array(v).astype(float)) if hasattr(v,'__iter__') else v) for k,v in hist_dict.items()}\n    res = {\n        'name': name,\n        'accuracy': acc,\n        'roc_auc': roc_auc,\n        'class_report': rep,\n        'conf_mat': cm,\n        'fpr': fpr,\n        'tpr': tpr,\n        'history': clean_hist\n    }\n    return res\n\nprint(\"Cell 2 loaded utilities.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:29:01.264814Z","iopub.execute_input":"2025-12-03T15:29:01.265199Z","iopub.status.idle":"2025-12-03T15:29:01.276319Z","shell.execute_reply.started":"2025-12-03T15:29:01.265172Z","shell.execute_reply":"2025-12-03T15:29:01.275530Z"}},"outputs":[{"name":"stdout","text":"Cell 2 loaded utilities.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **GAN-Fixed**","metadata":{}},{"cell_type":"code","source":"# ================================\n# CELL 3 — Vanilla GAN (Kaggle-optimized, NO early stopping)\n# - saves ONLY best generator + best discriminator weights (.weights.h5)\n# - runs ALL 1000 GAN epochs and ALL 50 classifier epochs\n# - no synthetic datasets saved, minimal PNGs + JSON\n# - OPTIMIZED: cached synthetic generation, tf.data for classifier\n# - FIX: uses actual y_train labels for real data (not all 1s)\n# ================================\nimport os, time, gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n\n# -------- CONFIG --------\nOUTPUT_DIR = \"/kaggle/working/dl-results-3\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nLATENT_DIM = 100\nEPOCHS_GAN = 1000          # run ALL 1000 epochs (no early stopping)\nBATCH = 32\nCLASSIFIER_EPOCHS = 50     # run ALL 50 epochs (no early stopping)\nSEED = 42\nSAVE_SIZE_CAP_BYTES = 2 * 1024**3   # 2 GiB safety cap (we'll warn if exceeded)\nLOG_EVERY = 100\nSYNTHETIC_CACHE_SIZE = None  # will be set to N_train (same as original code)\n\nnp.random.seed(SEED); tf.random.set_seed(SEED)\n\n# -------- load data splits (Cell 1 saved .npz) --------\nX_train, X_test, y_train, y_test = load_data_splits()\nX = X_train.astype(np.float32)\nFEATURES = X.shape[1]\nN_train = X.shape[0]\nSYNTHETIC_CACHE_SIZE = N_train  # match original: generate same amount as real data\nprint(f\"[GAN] features={FEATURES} | n_train={N_train}\")\n\n# -------- build generator & discriminator (unchanged arch) --------\ndef build_generator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(256, input_dim=LATENT_DIM),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(FEATURES, activation='tanh')\n    ], name=\"generator\")\n\ndef build_discriminator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(512, input_shape=(FEATURES,)),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ], name=\"discriminator\")\n\ngenerator = build_generator()\ndiscriminator = build_discriminator()\n\nopt_d = tf.keras.optimizers.Adam(0.0002, 0.5)\nopt_g = tf.keras.optimizers.Adam(0.0002, 0.5)\n\n# -------- prepare GAN model (compile with disc non-trainable for GAN-object) --------\ndiscriminator.trainable = False\nz = tf.keras.Input(shape=(LATENT_DIM,))\ngan_out = discriminator(generator(z))\ngan = tf.keras.Model(z, gan_out, name=\"gan_model\")\ngan.compile(optimizer=opt_g, loss=\"binary_crossentropy\")\n\n# Now compile discriminator separately for manual training loops\ndiscriminator.trainable = True\ndiscriminator.compile(optimizer=opt_d, loss=\"binary_crossentropy\")\n\n# -------- tf.data pipeline (fast + memory-safe) --------\nAUTOTUNE = tf.data.AUTOTUNE\nshuffle_buffer = min(10000, N_train)\nds = tf.data.Dataset.from_tensor_slices(X).shuffle(shuffle_buffer, seed=SEED).repeat().batch(BATCH).prefetch(AUTOTUNE)\nds_iter = iter(ds)\n\nreal_label = tf.ones((BATCH,1), tf.float32)\nfake_label = tf.zeros((BATCH,1), tf.float32)\n\n# -------- training step (tf.function for speed) --------\n@tf.function\ndef train_step(real_batch):\n    # discriminator on real\n    with tf.GradientTape() as tape_d_real:\n        pred_real = discriminator(real_batch, training=True)\n        loss_real = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, pred_real))\n    grads_real = tape_d_real.gradient(loss_real, discriminator.trainable_variables)\n    opt_d.apply_gradients(zip(grads_real, discriminator.trainable_variables))\n\n    # discriminator on fake\n    noise = tf.random.normal((BATCH, LATENT_DIM))\n    fake_batch = generator(noise, training=True)\n    with tf.GradientTape() as tape_d_fake:\n        pred_fake = discriminator(fake_batch, training=True)\n        loss_fake = tf.reduce_mean(tf.keras.losses.binary_crossentropy(fake_label, pred_fake))\n    grads_fake = tape_d_fake.gradient(loss_fake, discriminator.trainable_variables)\n    opt_d.apply_gradients(zip(grads_fake, discriminator.trainable_variables))\n\n    # generator step (try to fool discriminator) — compute grads manually\n    noise2 = tf.random.normal((BATCH, LATENT_DIM))\n    with tf.GradientTape() as tape_g:\n        gen_out = generator(noise2, training=True)\n        disc_out_for_g = discriminator(gen_out, training=False)   # freeze disc for generator update\n        loss_g = tf.reduce_mean(tf.keras.losses.binary_crossentropy(real_label, disc_out_for_g))\n    grads_g = tape_g.gradient(loss_g, generator.trainable_variables)\n    opt_g.apply_gradients(zip(grads_g, generator.trainable_variables))\n\n    return (loss_real + loss_fake) * 0.5, loss_g\n\n# -------- adversarial training (NO early stopping - run all epochs) --------\nprint(\"[GAN] Adversarial training started (NO early stopping)...\")\nd_losses, g_losses = [], []\nbest_g_loss = np.inf\ngen_best_path = os.path.join(OUTPUT_DIR, \"generator_best.weights.h5\")\n\nstart_time = time.time()\nfor epoch in range(EPOCHS_GAN):\n    real_batch = next(ds_iter)\n    d_val, g_val = train_step(real_batch)\n\n    d_losses.append(float(d_val))\n    g_losses.append(float(g_val))\n\n    # save best generator weights (but don't stop early)\n    cur_g = float(g_val)\n    if cur_g < best_g_loss - 1e-8:\n        best_g_loss = cur_g\n        generator.save_weights(gen_best_path)   # tiny file\n\n    # log progress\n    if (epoch % LOG_EVERY) == 0 or epoch == EPOCHS_GAN-1:\n        elapsed = time.time() - start_time\n        print(f\"[Epoch {epoch}/{EPOCHS_GAN}] D_loss={d_losses[-1]:.4f} | G_loss={g_losses[-1]:.4f} | best_g={best_g_loss:.4f} | elapsed={elapsed:.1f}s\")\n\nprint(f\"[GAN] Adversarial loop done in {time.time()-start_time:.1f}s. Best G loss: {best_g_loss:.5f}\")\nprint(\"Generator best weights:\", gen_best_path)\n\n# -------- OPTIMIZED: pre-generate synthetic samples in bulk (avoid per-batch predict calls) --------\n# FIX: Generate same amount as original (N_train samples) and use ACTUAL y_train labels\nprint(f\"[Classifier] Pre-generating {SYNTHETIC_CACHE_SIZE} synthetic samples...\")\nnoise_bulk = np.random.normal(0, 1, (SYNTHETIC_CACHE_SIZE, LATENT_DIM)).astype(np.float32)\nsynthetic_X = generator.predict(noise_bulk, batch_size=512, verbose=0)  # one bulk call\nsynthetic_y = np.zeros(SYNTHETIC_CACHE_SIZE, dtype=np.float32)          # synthetic = label 0\n\n# FIX: use ACTUAL y_train labels for real data (not all 1s!)\n# This matches original: combined_y = np.hstack((y, synthetic_labels))\ncombined_X = np.vstack([X, synthetic_X]).astype(np.float32)\ncombined_y = np.hstack([y_train.astype(np.float32), synthetic_y])  # ← KEY FIX\n\n# shuffle combined data\nperm = np.random.permutation(len(combined_X))\ncombined_X = combined_X[perm]\ncombined_y = combined_y[perm].reshape(-1, 1)\n\nprint(f\"[Classifier] Combined training set: {combined_X.shape[0]} samples (real + synthetic)\")\nprint(f\"[Classifier] Label distribution: 0={np.sum(combined_y==0)}, 1={np.sum(combined_y==1)}\")\n\n# -------- tf.data pipeline for classifier (faster than Python generator) --------\ntrain_ds = tf.data.Dataset.from_tensor_slices((combined_X, combined_y))\ntrain_ds = train_ds.shuffle(buffer_size=min(50000, len(combined_X)), seed=SEED)\ntrain_ds = train_ds.batch(BATCH).prefetch(AUTOTUNE)\n\n# validation data - use actual test labels\nval_ds = tf.data.Dataset.from_tensor_slices(\n    (X_test.astype(np.float32), y_test.reshape(-1,1).astype(np.float32))\n).batch(BATCH).prefetch(AUTOTUNE)\n\ndisc_best_path = os.path.join(OUTPUT_DIR, \"discriminator_best.weights.h5\")\n# ModelCheckpoint saves best weights only (no early stopping)\ncheckpoint = ModelCheckpoint(disc_best_path, monitor=\"val_accuracy\",\n                             save_best_only=True, save_weights_only=True, verbose=1)\n\n# Rebuild discriminator fresh for classifier training (avoid any leftover state)\ndiscriminator = build_discriminator()\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n                      loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nprint(\"[Classifier] Fine-tuning discriminator (NO early stopping - all 50 epochs)...\")\nhistory = discriminator.fit(\n    train_ds,\n    epochs=CLASSIFIER_EPOCHS,\n    validation_data=val_ds,\n    callbacks=[checkpoint],  # only checkpoint, no early stopping\n    verbose=1\n)\n\n# Load best weights\ndiscriminator.load_weights(disc_best_path)\nprint(\"Discriminator best weights loaded:\", disc_best_path)\n\n# -------- free memory from synthetic cache --------\ndel synthetic_X, combined_X, combined_y, noise_bulk\ngc.collect()\n\n# -------- evaluation & small PNGs (ROC + train curves) --------\ny_prob = discriminator.predict(X_test, verbose=0).ravel()\ny_pred = (y_prob >= 0.5).astype(int)\n\nacc = float(np.mean(y_pred == y_test))\nprint(f\"\\n=== Accuracy: {acc:.4f} ===\")\nprint(\"\\n=== Classification Report (Discriminator) ===\")\nprint(classification_report(y_test, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# ROC\ntry:\n    auc_val = roc_auc_score(y_test, y_prob)\n    print(f\"ROC-AUC: {auc_val:.4f}\")\nexcept Exception:\n    auc_val = None\nfpr, tpr, _ = roc_curve(y_test, y_prob)\n\n# plot ROC curve\nplt.figure(figsize=(5,5))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f\"AUC={auc_val:.3f}\" if auc_val else \"ROC\")\nplt.plot([0,1],[0,1],'k--', alpha=0.3)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Vanilla GAN Discriminator ROC\")\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, \"gan_discriminator_roc.png\"), dpi=100)\nplt.show()\nplt.close()\n\n# Train/val accuracy curves\nif history is not None:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    \n    # accuracy\n    axes[0].plot(history.history.get(\"accuracy\", []), label=\"train_acc\")\n    axes[0].plot(history.history.get(\"val_accuracy\", []), label=\"val_acc\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Accuracy\")\n    axes[0].set_title(\"Vanilla GAN - Accuracy\")\n    axes[0].legend()\n    \n    # loss\n    axes[1].plot(history.history.get(\"loss\", []), label=\"train_loss\")\n    axes[1].plot(history.history.get(\"val_loss\", []), label=\"val_loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].set_title(\"Vanilla GAN - Loss\")\n    axes[1].legend()\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, \"gan_train_val_curves.png\"), dpi=100)\n    plt.show()\n    plt.close()\n\n# -------- save JSON result entry (models_results.json via helper) --------\nres = make_result_dict(\"Vanilla_GAN\", discriminator, X_test, y_test, history)\nres.update({\n    \"best_generator_weights\": os.path.basename(gen_best_path),\n    \"best_discriminator_weights\": os.path.basename(disc_best_path),\n    \"gan_epochs_ran\": int(len(g_losses)),\n    \"d_losses\": d_losses[-10:],  # save only last 10 for JSON size\n    \"g_losses\": g_losses[-10:],\n    \"timestamp\": time.time()\n})\nsave_model_result(res)\nprint(\"[JSON] result appended to models_results.json\")\n\n# -------- storage guard: ensure saved files stay small (warn if > 2 GiB) --------\ndef human_mb(n): return f\"{n/1024**2:.2f} MB\"\ntotal_bytes = 0\nfor root, _, files in os.walk(OUTPUT_DIR):\n    for f in files:\n        total_bytes += os.path.getsize(os.path.join(root, f))\nif total_bytes > SAVE_SIZE_CAP_BYTES:\n    print(\"⚠️ WARNING: OUTPUT_DIR size > 2 GiB — consider removing large artifacts.\")\nprint(f\"Output directory size: {total_bytes/1024**2:.2f} MB\")\n\n# -------- cleanup --------\nK.clear_session()\ngc.collect()\n\nprint(\"✅ CELL 3 finished — only BEST weights saved (generator + discriminator) + PNGs + JSON.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:29:09.127417Z","iopub.execute_input":"2025-12-03T15:29:09.128222Z","execution_failed":"2025-12-03T19:53:13.808Z"}},"outputs":[{"name":"stdout","text":"[GAN] features=128 | n_train=3089910\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1764775763.852854    2551 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1764775763.853475    2551 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"[GAN] Adversarial training started (NO early stopping)...\n[Epoch 0/1000] D_loss=0.7219 | G_loss=0.7106 | best_g=0.7106 | elapsed=4.0s\n[Epoch 100/1000] D_loss=0.6071 | G_loss=0.8265 | best_g=0.5312 | elapsed=4.7s\n[Epoch 200/1000] D_loss=0.6482 | G_loss=0.9554 | best_g=0.5312 | elapsed=5.3s\n[Epoch 300/1000] D_loss=0.7745 | G_loss=0.7830 | best_g=0.5312 | elapsed=5.8s\n[Epoch 400/1000] D_loss=0.6837 | G_loss=0.8747 | best_g=0.5312 | elapsed=6.4s\n[Epoch 500/1000] D_loss=0.5650 | G_loss=0.9658 | best_g=0.5312 | elapsed=7.0s\n[Epoch 600/1000] D_loss=0.6833 | G_loss=0.9006 | best_g=0.5312 | elapsed=7.5s\n[Epoch 700/1000] D_loss=0.7142 | G_loss=0.7888 | best_g=0.5312 | elapsed=8.1s\n[Epoch 800/1000] D_loss=0.6463 | G_loss=0.7163 | best_g=0.5312 | elapsed=8.7s\n[Epoch 900/1000] D_loss=1.0218 | G_loss=0.7003 | best_g=0.5312 | elapsed=9.2s\n[Epoch 999/1000] D_loss=0.6199 | G_loss=1.0684 | best_g=0.5312 | elapsed=9.8s\n[GAN] Adversarial loop done in 9.8s. Best G loss: 0.53120\nGenerator best weights: /kaggle/working/dl-results-3/generator_best.weights.h5\n[Classifier] Pre-generating 3089910 synthetic samples...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1764775793.762480    2591 service.cc:148] XLA service 0x7c6a84007170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1764775793.763328    2591 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1764775793.763349    2591 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1764775793.848361    2591 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1764775794.233780    2591 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"[Classifier] Combined training set: 6179820 samples (real + synthetic)\n[Classifier] Label distribution: 0=4636271, 1=1543549\n[Classifier] Fine-tuning discriminator (NO early stopping - all 50 epochs)...\nEpoch 1/50\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7930 - loss: 0.3279\nEpoch 1: val_accuracy improved from -inf to 0.68134, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 2ms/step - accuracy: 0.7930 - loss: 0.3279 - val_accuracy: 0.6813 - val_loss: 0.5616\nEpoch 2/50\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.2897\nEpoch 2: val_accuracy improved from 0.68134 to 0.71285, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.2897 - val_accuracy: 0.7129 - val_loss: 0.5225\nEpoch 3/50\n\u001b[1m193116/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.2786\nEpoch 3: val_accuracy improved from 0.71285 to 0.72896, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.2786 - val_accuracy: 0.7290 - val_loss: 0.5020\nEpoch 4/50\n\u001b[1m193115/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.2716\nEpoch 4: val_accuracy improved from 0.72896 to 0.74230, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.2716 - val_accuracy: 0.7423 - val_loss: 0.4869\nEpoch 5/50\n\u001b[1m193110/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.2670\nEpoch 5: val_accuracy improved from 0.74230 to 0.74835, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.2670 - val_accuracy: 0.7484 - val_loss: 0.4764\nEpoch 6/50\n\u001b[1m193105/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.2635\nEpoch 6: val_accuracy improved from 0.74835 to 0.75580, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.2635 - val_accuracy: 0.7558 - val_loss: 0.4699\nEpoch 7/50\n\u001b[1m193114/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.2608\nEpoch 7: val_accuracy improved from 0.75580 to 0.76287, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.2608 - val_accuracy: 0.7629 - val_loss: 0.4609\nEpoch 8/50\n\u001b[1m193110/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.2589\nEpoch 8: val_accuracy improved from 0.76287 to 0.76685, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.2589 - val_accuracy: 0.7669 - val_loss: 0.4536\nEpoch 9/50\n\u001b[1m193111/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.2572\nEpoch 9: val_accuracy improved from 0.76685 to 0.76899, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.2572 - val_accuracy: 0.7690 - val_loss: 0.4506\nEpoch 10/50\n\u001b[1m193114/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.2556\nEpoch 10: val_accuracy improved from 0.76899 to 0.77234, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.2556 - val_accuracy: 0.7723 - val_loss: 0.4487\nEpoch 11/50\n\u001b[1m193118/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.2541\nEpoch 11: val_accuracy improved from 0.77234 to 0.77546, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 3ms/step - accuracy: 0.8605 - loss: 0.2541 - val_accuracy: 0.7755 - val_loss: 0.4424\nEpoch 12/50\n\u001b[1m193115/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.2529\nEpoch 12: val_accuracy improved from 0.77546 to 0.77941, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.2529 - val_accuracy: 0.7794 - val_loss: 0.4388\nEpoch 13/50\n\u001b[1m193103/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.2520\nEpoch 13: val_accuracy did not improve from 0.77941\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.2520 - val_accuracy: 0.7788 - val_loss: 0.4383\nEpoch 14/50\n\u001b[1m193105/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.2511\nEpoch 14: val_accuracy did not improve from 0.77941\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.2511 - val_accuracy: 0.7769 - val_loss: 0.4403\nEpoch 15/50\n\u001b[1m193112/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.2508\nEpoch 15: val_accuracy improved from 0.77941 to 0.78511, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.2508 - val_accuracy: 0.7851 - val_loss: 0.4315\nEpoch 16/50\n\u001b[1m193109/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.2495\nEpoch 16: val_accuracy improved from 0.78511 to 0.78556, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.2495 - val_accuracy: 0.7856 - val_loss: 0.4301\nEpoch 17/50\n\u001b[1m193103/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.2491\nEpoch 17: val_accuracy improved from 0.78556 to 0.78754, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.2491 - val_accuracy: 0.7875 - val_loss: 0.4247\nEpoch 18/50\n\u001b[1m193111/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.2482\nEpoch 18: val_accuracy improved from 0.78754 to 0.78799, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.2482 - val_accuracy: 0.7880 - val_loss: 0.4247\nEpoch 19/50\n\u001b[1m193104/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.2480\nEpoch 19: val_accuracy improved from 0.78799 to 0.78986, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.2480 - val_accuracy: 0.7899 - val_loss: 0.4232\nEpoch 20/50\n\u001b[1m193118/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.2476\nEpoch 20: val_accuracy did not improve from 0.78986\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.2476 - val_accuracy: 0.7864 - val_loss: 0.4249\nEpoch 21/50\n\u001b[1m193116/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.2469\nEpoch 21: val_accuracy did not improve from 0.78986\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.2469 - val_accuracy: 0.7876 - val_loss: 0.4221\nEpoch 22/50\n\u001b[1m193105/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.2466\nEpoch 22: val_accuracy did not improve from 0.78986\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.2466 - val_accuracy: 0.7889 - val_loss: 0.4216\nEpoch 23/50\n\u001b[1m193106/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.2463\nEpoch 23: val_accuracy did not improve from 0.78986\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.2463 - val_accuracy: 0.7882 - val_loss: 0.4205\nEpoch 24/50\n\u001b[1m193111/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.2459\nEpoch 24: val_accuracy improved from 0.78986 to 0.79402, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.2459 - val_accuracy: 0.7940 - val_loss: 0.4166\nEpoch 25/50\n\u001b[1m193113/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.2455\nEpoch 25: val_accuracy improved from 0.79402 to 0.79523, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.2455 - val_accuracy: 0.7952 - val_loss: 0.4165\nEpoch 26/50\n\u001b[1m193109/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.2450\nEpoch 26: val_accuracy did not improve from 0.79523\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.2450 - val_accuracy: 0.7941 - val_loss: 0.4175\nEpoch 27/50\n\u001b[1m193113/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.2449\nEpoch 27: val_accuracy improved from 0.79523 to 0.79679, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.2449 - val_accuracy: 0.7968 - val_loss: 0.4161\nEpoch 28/50\n\u001b[1m193106/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.2445\nEpoch 28: val_accuracy improved from 0.79679 to 0.79827, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.2445 - val_accuracy: 0.7983 - val_loss: 0.4149\nEpoch 29/50\n\u001b[1m193111/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.2443\nEpoch 29: val_accuracy did not improve from 0.79827\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.2443 - val_accuracy: 0.7979 - val_loss: 0.4159\nEpoch 30/50\n\u001b[1m193109/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.2441\nEpoch 30: val_accuracy did not improve from 0.79827\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.2441 - val_accuracy: 0.7982 - val_loss: 0.4123\nEpoch 31/50\n\u001b[1m193114/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.2436\nEpoch 31: val_accuracy improved from 0.79827 to 0.79842, saving model to /kaggle/working/dl-results-3/discriminator_best.weights.h5\n\u001b[1m193120/193120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.2436 - val_accuracy: 0.7984 - val_loss: 0.4121\nEpoch 32/50\n\u001b[1m110030/193120\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.2429","output_type":"stream"}],"execution_count":null}]}