{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13509254,"sourceType":"datasetVersion","datasetId":5468552}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:15:41.545335Z","iopub.execute_input":"2025-11-20T09:15:41.545489Z","iopub.status.idle":"2025-11-20T09:15:43.612692Z","shell.execute_reply.started":"2025-11-20T09:15:41.545475Z","shell.execute_reply":"2025-11-20T09:15:43.611861Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010030rest 20160324 1054..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020025rest 20150713 1519..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010013rest 20150703 1333..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020016rest 20150701 1040..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020015_rest 20150630 1527.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010022restnew 20150724 14.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020027rest 20150713 1049..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010008_rest 20150619 1653.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010011rest 20150625 1516..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020029rest 20150715 1316..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020023restnew 20150709 10.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010012rest 20150626 1026..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030020_rest 20151230 1416.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010018rest 20150716 1237..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010002rest 20150416 1017..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020010rest 20150625 1224..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010016rest 20150710 1220..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020008rest 20150624 1711..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010024rest 20150814 1504..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030004_rest 20151026 1930.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020020rest 20150703 1754..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020018rest 20150702 1651..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010010rest 20150624 1447..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030002rest_new 20151022 1.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010033rest 20160331 1239..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020019rest 20150703 1036..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010005rest 20150507 0907..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030007_rest 20151103 2032.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030017_rest 20151208 1329.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030018_rest 20151208 1443.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020013rest 20150629 1607..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010026rest 20160311 1421..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030006_rest 20151103 1725.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010023rest 20150729 1929..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020021rest 20150707 1720..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020026_rest 20150714 1413.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030019_rest 20151230 1314.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030005rest 20151026 2103..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010015rest 20150709 1456..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030009_rest 20151105 1113.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010006rest 20150528 0928..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030003_rest 20151022 1155.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010004rest 20150427 1335..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020022rest 20150707 1452..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030021rest 20160105 1141..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010036_rest 20160408 1418.csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010034rest 20160407 0938..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010028rest 20160317 1538..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02030014rest 20151117 1441..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02010019rest 20150716 1440..csv\n/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2/02020014_rest 20150630 1023.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030017erp 20151208 1351-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010002erp 20150416 1131-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010011erp 20150625 1545-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010024erp 20150814 1523-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010018erp 20150716 1310-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010010erp 20150624 1508-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020025_erp 20150713 1541-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010030erp 20160324 0915-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030021erp 20160105 1204-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020020_erp 20150703 1810-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020027_erp 20150713 1116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030020_erp 20151230 1443-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010015erp 20150709 1534-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010013erp 20150703 1353-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010023erp 20150729 1955-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030009erp 20151105 1207-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010025erp 20160311 1225-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010021erp 20150805 1818-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020016_erp 20150701 1054-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010034erp 20160407 0959-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020019_erp 20150703 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030005erp 20151026 2116-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020013_erp 20150629 1622-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020029_erp 20150715 1401-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010019erp 20150716 1544-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020026_erp 20150714 1428-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010033erp 20160331 1307-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010005erp 20150507 0938-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010006erp 20150528 1007-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030019_erp 20151230 1331-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030006 20151103 1801-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010004erp 20141219 1602-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020010_erp 20150625 1244-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030007 20151103 2129-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030014erp 20151117 1419-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02030002erp_new 20151022 14-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020015_erp 20150630 1547-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020021_erp 20150707 1751-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010012erp 20150626 1059-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010028erp 20160317 1554-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020022_erp 20150707 1515-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020018_erp 20150702 1721-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020023_erpnew 20150709 110-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010026erp 20160311 1441-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010016erp 20150710 1329-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010008_erp(n) 20150619 1709-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020008_erp 20150624 1740-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010036erp 20160408 1452-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02010022erp 20150724 1457-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/raw-csv-actual/raw-csv-actual/csv_from_raw1/02020014_erp 20150630 1052-preprocessed.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/18.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/20.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/07.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/24.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/11.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/17.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/16.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/19.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/26.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/28.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/13.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/23.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/14.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/22.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/06.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/05.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/12.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/09.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/04.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/01.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/03.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/15.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/all_audio_features.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/10.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/08.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/25.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/29.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/21.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/27.csv\n/kaggle/input/preprocessed-raw-mat-csv/audio_features_csv_2/02.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Setup, load & preprocessing, save splits**","metadata":{}},{"cell_type":"code","source":"# CELL 1: Setup + Load + Preprocess + Save splits\nimport os, re, math, json, warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import IncrementalPCA\n\n# CONFIG\nDATA_DIR    = '/kaggle/input/preprocessed-raw-mat-csv/mat-csv-actual/mat-csv-actual/csv_files_from_mat2'\nOUTPUT_DIR  = '/kaggle/working/dl_results'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nSAMPLE_FRAC      = 1.0        # set 0.1 for quick tests\nUSE_IPCA         = True\nIPCA_COMPONENTS  = 128\nIPCA_BATCH       = 5000\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# GPU memory growth (optional)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor g in gpus:\n    try:\n        tf.config.experimental.set_memory_growth(g, True)\n    except Exception:\n        pass\n\n# helpers\ndef detect_eeg_columns(columns):\n    regex = re.compile(r'^(?:EEG[_\\-\\s]?|E[_\\-\\s]?)(0*?)(\\d{1,3})$', flags=re.I)\n    found = {}\n    for c in columns:\n        m = regex.match(c.strip())\n        if m:\n            num = int(m.group(2))\n            if 1 <= num <= 128:\n                found[num] = c\n    if found:\n        return [found[i] for i in sorted(found.keys())]\n    # fallback\n    return [c for c in columns if re.match(r'^(E|EEG)\\d+', c, flags=re.I)]\n\ndef to_binary_label_series(s):\n    s = s.dropna()\n    if s.empty: return None\n    s_num = pd.to_numeric(s, errors='coerce')\n    if s_num.notna().all():\n        uniq = set(np.unique(s_num))\n        if uniq.issubset({0,1}): return s_num.astype(int)\n        if uniq.issubset({1,2}): return s_num.map({1:0,2:1}).astype(int)\n        med = float(s_num.median()); return (s_num > med).astype(int)\n    s_str = s.astype(str)\n    unique_vals = s_str.unique()\n    if len(unique_vals) == 1: return s_str.map({unique_vals[0]:0}).astype(int)\n    if len(unique_vals) == 2:\n        le = LabelEncoder().fit(unique_vals)\n        return pd.Series(le.transform(s_str), index=s_str.index).astype(int)\n    mode_val = s_str.mode().iat[0]; return (s_str != mode_val).astype(int)\n\n# 1) Read CSVs\ncsvs = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.csv')])\nif len(csvs)==0:\n    raise RuntimeError(\"No CSV files in DATA_DIR\")\nprint(\"Found\", len(csvs), \"CSV files.\")\n\nparts = []\nfor fn in csvs:\n    path = os.path.join(DATA_DIR, fn)\n    df = pd.read_csv(path, engine='python')\n    if SAMPLE_FRAC is not None and 0 < SAMPLE_FRAC < 1.0:\n        df = df.sample(frac=SAMPLE_FRAC, random_state=SEED)\n    df['__source_file'] = os.path.splitext(fn)[0]\n    parts.append(df)\ncombined = pd.concat(parts, ignore_index=True)\nprint(\"Combined shape:\", combined.shape)\n\n# 2) label detection (prefer epoch, label, condition)\nlabel_cols_try = ['epoch','label','condition','cond','target']\nlabel_series = None\nfor c in label_cols_try:\n    if c in combined.columns:\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Using\", c, \"as labels.\")\n            break\nif label_series is None:\n    # fallback search\n    for c in combined.columns:\n        if c.startswith('__'): continue\n        s = to_binary_label_series(combined[c])\n        if s is not None:\n            label_series = pd.Series(index=combined.index, dtype=int)\n            label_series.loc[combined[c].dropna().index] = s\n            label_series = label_series.fillna(0).astype(int)\n            print(\"Fallback using\", c, \"as labels.\")\n            break\nif label_series is None:\n    raise RuntimeError(\"No suitable label column found. Ensure 'epoch'/'label' exists.\")\n\nprint(\"Label distribution:\", label_series.value_counts().to_dict())\nif label_series.nunique() <= 1:\n    print(\"Detected single class after mapping — abort and inspect label columns.\")\n    raise RuntimeError(\"Single-class dataset. Fix labels.\")\n\ncombined['__label'] = label_series.astype(int)\n\n# 3) Detect EEG columns & form feature matrix\neeg_cols = detect_eeg_columns(combined.columns)\nif not eeg_cols:\n    raise RuntimeError(\"No EEG columns detected; check column names.\")\nprint(\"Detected EEG columns:\", len(eeg_cols))\n# drop known metadata columns\ndrop_cols = {'time','condition','label','epoch','__source_file','__label'}\nfeature_cols = [c for c in eeg_cols if c not in drop_cols]\nif len(feature_cols) == 0:\n    raise RuntimeError(\"No feature columns after filtering.\")\nX_full = combined[feature_cols].to_numpy(dtype=np.float32)\ny = combined['__label'].to_numpy(dtype=np.int32)\nprint(\"X_full shape:\", X_full.shape, \"y shape:\", y.shape)\n\n# impute NaNs\nif np.isnan(X_full).any():\n    col_means = np.nanmean(X_full, axis=0)\n    inds = np.where(np.isnan(X_full)); X_full[inds] = np.take(col_means, inds[1])\n    print(\"Imputed NaNs.\")\n\n# 4) Optional IncrementalPCA\nif USE_IPCA and IPCA_COMPONENTS is not None and 0 < IPCA_COMPONENTS < X_full.shape[1]:\n    print(\"Running IncrementalPCA...\")\n    ipca = IncrementalPCA(n_components=IPCA_COMPONENTS)\n    n = X_full.shape[0]; bs = IPCA_BATCH\n    for i in range(0, n, bs):\n        ipca.partial_fit(X_full[i:i+bs])\n    X_reduced = np.empty((n, IPCA_COMPONENTS), dtype=np.float32)\n    for i in range(0, n, bs):\n        X_reduced[i:i+bs] = ipca.transform(X_full[i:i+bs]).astype(np.float32)\n    X = X_reduced\nelse:\n    X = X_full\nprint(\"Post-PCA shape:\", X.shape)\n\n# 5) scale and split (save splits for model cells)\nscaler = StandardScaler()\nX = scaler.fit_transform(X).astype(np.float32)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n# persist splits so model cells can load them\nnp.savez_compressed(os.path.join(OUTPUT_DIR, 'data_split.npz'),\n                    X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\nprint(\"Saved data_split.npz to\", OUTPUT_DIR)\n# create empty models_results.json if not exists\nres_path = os.path.join(OUTPUT_DIR, 'models_results.json')\nif not os.path.exists(res_path):\n    with open(res_path,'w') as f: json.dump([], f)\nprint(\"Cell 1 done.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:15:43.614336Z","iopub.execute_input":"2025-11-20T09:15:43.614665Z","iopub.status.idle":"2025-11-20T09:26:54.050615Z","shell.execute_reply.started":"2025-11-20T09:15:43.614646Z","shell.execute_reply":"2025-11-20T09:26:54.049760Z"}},"outputs":[{"name":"stderr","text":"2025-11-20 09:15:46.698153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763630146.895604      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763630146.959594      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Found 51 CSV files.\nCombined shape: (3862388, 133)\nUsing epoch as labels.\nLabel distribution: {0: 1932951, 1: 1929437}\nDetected EEG columns: 128\nX_full shape: (3862388, 128) y shape: (3862388,)\nPost-PCA shape: (3862388, 128)\nSaved data_split.npz to /kaggle/working/dl_results\nCell 1 done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **Utility functions**","metadata":{}},{"cell_type":"code","source":"# CELL 2: Utility functions for model cells (run once)\nimport os, json, numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n\nOUTPUT_DIR = '/kaggle/working/dl_results'\ndef load_data_splits():\n    p = os.path.join(OUTPUT_DIR, 'data_split.npz')\n    d = np.load(p)\n    return d['X_train'], d['X_test'], d['y_train'], d['y_test']\n\ndef save_model_result(res):\n    \"\"\"Append JSON-serializable result dict to models_results.json\"\"\"\n    p = os.path.join(OUTPUT_DIR, 'models_results.json')\n    lst = []\n    if os.path.exists(p):\n        with open(p,'r') as f:\n            try:\n                lst = json.load(f)\n            except Exception:\n                lst = []\n    lst.append(res)\n    with open(p,'w') as f:\n        json.dump(lst, f)\n\ndef make_result_dict(name, model, X_test, y_test, history=None):\n    # predict probabilities where possible\n    try:\n        probs = model.predict(X_test, verbose=0).ravel()\n    except Exception:\n        # if model expects 3D or 4D, let caller reshape X_test appropriately before calling make_result_dict\n        probs = model.predict(X_test, verbose=0).ravel()\n    preds = (probs >= 0.5).astype(int)\n    acc = float(accuracy_score(y_test, preds))\n    try:\n        roc_auc = float(roc_auc_score(y_test, probs))\n    except Exception:\n        roc_auc = None\n    rep = classification_report(y_test, preds)\n    cm = confusion_matrix(y_test, preds).tolist()\n    try:\n        fpr,tpr,_ = roc_curve(y_test, probs)\n        fpr = fpr.tolist(); tpr = tpr.tolist()\n    except Exception:\n        fpr,tpr = [], []\n    hist_dict = history.history if history is not None else {}\n    # convert numpy types in hist to lists\n    clean_hist = {k: (list(np.array(v).astype(float)) if hasattr(v,'__iter__') else v) for k,v in hist_dict.items()}\n    res = {\n        'name': name,\n        'accuracy': acc,\n        'roc_auc': roc_auc,\n        'class_report': rep,\n        'conf_mat': cm,\n        'fpr': fpr,\n        'tpr': tpr,\n        'history': clean_hist\n    }\n    return res\n\nprint(\"Cell 2 loaded utilities.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:26:54.051599Z","iopub.execute_input":"2025-11-20T09:26:54.051947Z","iopub.status.idle":"2025-11-20T09:26:54.062174Z","shell.execute_reply.started":"2025-11-20T09:26:54.051921Z","shell.execute_reply":"2025-11-20T09:26:54.061484Z"}},"outputs":[{"name":"stdout","text":"Cell 2 loaded utilities.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **GAN**","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# CELL 3 — Lightweight Stabilized GAN (1000 epochs)\n# Saves ONLY tiny .h5 weights + plots + JSON result\n# ============================================================\n\nimport os, time, gc\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n\nOUTPUT_DIR = '/kaggle/working/dl_results'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nLATENT_DIM = 100\nEPOCHS_GAN = 1000\nBATCH = 64\nSEED = 42\nnp.random.seed(SEED); tf.random.set_seed(SEED)\n\n# ---------------------------\n# Load data splits\n# ---------------------------\nX_train, X_test, y_train, y_test = load_data_splits()\nX = X_train.astype(np.float32)\nFEATURES = X.shape[1]\nN_train = X.shape[0]\nprint(f\"[GAN] features={FEATURES} | n_train={N_train}\")\n\n# ---------------------------\n# Generator & Discriminator\n# ---------------------------\ndef build_generator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(256, input_dim=LATENT_DIM),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(1024),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dense(FEATURES, activation='tanh')\n    ], name=\"generator\")\n\ndef build_discriminator():\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(512, input_shape=(FEATURES,)),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ], name=\"discriminator\")\n\ngenerator = build_generator()\ndiscriminator = build_discriminator()\n\nopt_d = tf.keras.optimizers.Adam(0.0002, 0.5)\nopt_g = tf.keras.optimizers.Adam(0.0002, 0.5)\n\n@tf.function\ndef d_loss(real_s, fake_s): return tf.reduce_mean(fake_s) - tf.reduce_mean(real_s)\n\n@tf.function\ndef g_loss(fake_s): return -tf.reduce_mean(fake_s)\n\nWEIGHT_CLIP = 0.01\nDISC_STEPS = 3\n\n@tf.function\ndef train_step(real_batch):\n    batch = tf.shape(real_batch)[0]\n    \n    for _ in tf.range(DISC_STEPS):\n        noise = tf.random.normal((batch, LATENT_DIM))\n        with tf.GradientTape() as tape_d:\n            fake = generator(noise, training=True)\n            real_out = discriminator(real_batch, training=True)\n            fake_out = discriminator(fake, training=True)\n            ld = d_loss(real_out, fake_out)\n        grads_d = tape_d.gradient(ld, discriminator.trainable_variables)\n        opt_d.apply_gradients(zip(grads_d, discriminator.trainable_variables))\n        for v in discriminator.trainable_variables:\n            v.assign(tf.clip_by_value(v, -WEIGHT_CLIP, WEIGHT_CLIP))\n\n    noise = tf.random.normal((batch, LATENT_DIM))\n    with tf.GradientTape() as tape_g:\n        fake = generator(noise, training=True)\n        fake_out = discriminator(fake, training=True)\n        lg = g_loss(fake_out)\n    grads_g = tape_g.gradient(lg, generator.trainable_variables)\n    opt_g.apply_gradients(zip(grads_g, generator.trainable_variables))\n\n    return ld, lg\n\n# ---------------------------\n# GAN Training\n# ---------------------------\nd_losses, g_losses = [], []\nprint(\"[GAN] Training...\")\n\nfor epoch in range(EPOCHS_GAN):\n    if epoch > 0 and epoch % 200 == 0:\n        opt_d.learning_rate.assign(opt_d.learning_rate * 0.5)\n        opt_g.learning_rate.assign(opt_g.learning_rate * 0.5)\n\n    idx = np.random.randint(0, N_train, BATCH)\n    real_batch = X[idx]\n    ld, lg = train_step(real_batch)\n    d_losses.append(float(ld)); g_losses.append(float(lg))\n\n    if epoch % 50 == 0:\n        print(f\"Epoch {epoch}/{EPOCHS_GAN} | D={d_losses[-1]:.4f} G={g_losses[-1]:.4f}\")\n\nprint(\"[GAN] Training Complete\")\n\n# ---------------------------\n# Generate synthetic (memory safe)\n# ---------------------------\ndef generate_in_batches(model, n_samples, batch=2048):\n    out = []\n    for i in range(0, n_samples, batch):\n        b = min(batch, n_samples - i)\n        noise = np.random.normal(0,1,(b, LATENT_DIM)).astype(np.float32)\n        out.append(model.predict(noise, verbose=0))\n    return np.vstack(out)\n\nsynthetic = generate_in_batches(generator, N_train)\n\n# ---------------------------\n# Train classifier version of discriminator\n# ---------------------------\ncombined_X = np.vstack([X, synthetic]).astype(np.float32)\ncombined_y = np.hstack([y_train, np.zeros(len(synthetic), dtype=np.int32)])\n\n# *** FIX: filename must end with 'weights.h5' when save_weights_only=True\ndisc_best_path = os.path.join(OUTPUT_DIR, \"disc_classifier_best.weights.h5\")\n\ncheckpoint = ModelCheckpoint(disc_best_path, save_best_only=True,\n                             save_weights_only=True, monitor='val_loss', verbose=0)\n# early = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002,0.5),\n                      loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nhistory = discriminator.fit(\n    combined_X, combined_y,\n    epochs=100, batch_size=64,\n    validation_split=0.2,\n    callbacks=checkpoint,\n    verbose=1\n)\n\n# Save final generator weights (use .weights.h5 to be consistent)\ngenerator.save_weights(os.path.join(OUTPUT_DIR,\"gan_generator_last.weights.h5\"))\n\n# ---------------------------\n# Evaluate\n# ---------------------------\ny_prob = discriminator.predict(X_test, verbose=0).ravel()\ny_pred = (y_prob >= 0.5).astype(int)\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))\n\n# ---------------------------\n# Save results to JSON (was missing)\n# ---------------------------\ngan_result = make_result_dict(\n    name=\"GAN_Augmented_Classifier\",\n    model=discriminator,\n    X_test=X_test,\n    y_test=y_test,\n    history=history\n)\nsave_model_result(gan_result)\nprint(\"[JSON] GAN result appended.\")\n\n# ---------------------------\n# Save essential PNG plots\n# ---------------------------\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nauc_val = roc_auc_score(y_test, y_prob)\nplt.figure(figsize=(5,5))\nplt.plot(fpr, tpr, label=f\"AUC={auc_val:.3f}\")\nplt.plot([0,1],[0,1],'k--')\nplt.title(\"GAN ROC\")\nplt.legend(); plt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_roc_2.png\"), dpi=100)\nplt.close()\n\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(4,4))\nplt.imshow(cm, cmap=\"Blues\")\nplt.colorbar()\nplt.title(\"GAN Confusion Matrix\")\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_cm_2.png\"), dpi=100)\nplt.close()\n\nplt.figure(figsize=(6,3))\nplt.plot(history.history.get(\"accuracy\",[]), label=\"train\")\nplt.plot(history.history.get(\"val_accuracy\",[]), label=\"val\")\nplt.title(\"GAN Train/Val Accuracy\")\nplt.legend(); plt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_acc_2.png\"), dpi=100)\nplt.close()\n\nplt.figure(figsize=(6,3))\nplt.plot(history.history.get(\"loss\",[]), label=\"train\")\nplt.plot(history.history.get(\"val_loss\",[]), label=\"val\")\nplt.title(\"GAN Train/Val Loss\")\nplt.legend(); plt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR,\"gan_loss_2.png\"), dpi=100)\nplt.close()\n\n# Cleanup\nK.clear_session()\ngc.collect()\nprint(\"✅ GAN Cell Completed (Tiny + JSON saved + Weights saved)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:48:58.109296Z","iopub.execute_input":"2025-11-20T09:48:58.109672Z","iopub.status.idle":"2025-11-20T15:38:03.531986Z","shell.execute_reply.started":"2025-11-20T09:48:58.109646Z","shell.execute_reply":"2025-11-20T15:38:03.531323Z"}},"outputs":[{"name":"stdout","text":"[GAN] features=128 | n_train=3089910\n[GAN] Training...\nEpoch 0/1000 | D=-0.0001 G=-0.4997\nEpoch 50/1000 | D=-0.0390 G=-0.4883\nEpoch 100/1000 | D=0.0038 G=-0.5284\nEpoch 150/1000 | D=-0.0498 G=-0.4673\nEpoch 200/1000 | D=-0.0445 G=-0.4572\nEpoch 250/1000 | D=-0.0235 G=-0.5066\nEpoch 300/1000 | D=-0.0066 G=-0.4862\nEpoch 350/1000 | D=-0.0446 G=-0.5076\nEpoch 400/1000 | D=-0.0427 G=-0.4669\nEpoch 450/1000 | D=-0.0253 G=-0.5079\nEpoch 500/1000 | D=0.0310 G=-0.5597\nEpoch 550/1000 | D=0.0152 G=-0.4661\nEpoch 600/1000 | D=-0.0165 G=-0.5054\nEpoch 650/1000 | D=-0.0108 G=-0.5085\nEpoch 700/1000 | D=-0.0008 G=-0.5419\nEpoch 750/1000 | D=-0.0393 G=-0.4602\nEpoch 800/1000 | D=-0.0027 G=-0.4969\nEpoch 850/1000 | D=-0.0128 G=-0.5023\nEpoch 900/1000 | D=-0.0094 G=-0.5064\nEpoch 950/1000 | D=-0.0111 G=-0.5135\n[GAN] Training Complete\nEpoch 1/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.4353 - val_accuracy: 1.0000 - val_loss: 0.0064\nEpoch 2/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.3819 - val_accuracy: 1.0000 - val_loss: 0.0048\nEpoch 3/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.3646 - val_accuracy: 1.0000 - val_loss: 0.0040\nEpoch 4/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.3540 - val_accuracy: 1.0000 - val_loss: 0.0035\nEpoch 5/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.3465 - val_accuracy: 1.0000 - val_loss: 0.0030\nEpoch 6/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.3409 - val_accuracy: 1.0000 - val_loss: 0.0024\nEpoch 7/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.3364 - val_accuracy: 1.0000 - val_loss: 0.0029\nEpoch 8/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.3335 - val_accuracy: 1.0000 - val_loss: 0.0024\nEpoch 9/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3301 - val_accuracy: 1.0000 - val_loss: 0.0024\nEpoch 10/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.3279 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 11/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3257 - val_accuracy: 1.0000 - val_loss: 0.0029\nEpoch 12/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.3240 - val_accuracy: 1.0000 - val_loss: 0.0026\nEpoch 13/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.3224 - val_accuracy: 1.0000 - val_loss: 0.0026\nEpoch 14/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.3207 - val_accuracy: 1.0000 - val_loss: 0.0025\nEpoch 15/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.3193 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 16/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.3183 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 17/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3176 - val_accuracy: 1.0000 - val_loss: 0.0026\nEpoch 18/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.3161 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 19/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.3152 - val_accuracy: 1.0000 - val_loss: 0.0024\nEpoch 20/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3143 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 21/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.3132 - val_accuracy: 1.0000 - val_loss: 0.0024\nEpoch 22/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3128 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 23/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.3121 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 24/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.3117 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 25/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3107 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 26/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3103 - val_accuracy: 1.0000 - val_loss: 0.0025\nEpoch 27/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3096 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 28/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3091 - val_accuracy: 0.9999 - val_loss: 0.0031\nEpoch 29/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.3084 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 30/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.3081 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 31/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3078 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 32/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3075 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 33/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3072 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 34/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3063 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 35/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3055 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 36/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3054 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 37/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3056 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 38/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.3051 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 39/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3053 - val_accuracy: 0.9999 - val_loss: 0.0026\nEpoch 40/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3041 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 41/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3038 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 42/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3040 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 43/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3039 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 44/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3035 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 45/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.3033 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 46/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3031 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 47/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.3029 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 48/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3027 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 49/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3019 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 50/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3017 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 51/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.3020 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 52/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3017 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 53/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3016 - val_accuracy: 0.9999 - val_loss: 0.0026\nEpoch 54/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3010 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 55/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3010 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 56/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3009 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 57/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3008 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 58/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8384 - loss: 0.3004 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 59/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3007 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 60/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.2998 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 61/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.2997 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 62/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3001 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 63/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.2998 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 64/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.2997 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 65/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.2996 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 66/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.2990 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 67/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.2991 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 68/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.2989 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 69/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.2992 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 70/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.2991 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 71/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.2987 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 72/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.2983 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 73/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.2984 - val_accuracy: 0.9999 - val_loss: 0.0021\nEpoch 74/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.2979 - val_accuracy: 0.9999 - val_loss: 0.0020\nEpoch 75/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.2982 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 76/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.2980 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 77/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.2979 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 78/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.2979 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 79/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.2976 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 80/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.2978 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 81/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.2978 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 82/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.2980 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 83/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.2973 - val_accuracy: 1.0000 - val_loss: 0.0014\nEpoch 84/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.2973 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 85/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.2973 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 86/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.2974 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 87/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.2970 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 88/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.2968 - val_accuracy: 1.0000 - val_loss: 0.0020\nEpoch 89/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.2967 - val_accuracy: 0.9999 - val_loss: 0.0019\nEpoch 90/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.2969 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 91/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.2967 - val_accuracy: 1.0000 - val_loss: 0.0017\nEpoch 92/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.2962 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 93/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.2968 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 94/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.2965 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 95/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.2959 - val_accuracy: 1.0000 - val_loss: 0.0019\nEpoch 96/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.2964 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 97/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.2960 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 98/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.2960 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 99/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.2963 - val_accuracy: 1.0000 - val_loss: 0.0021\nEpoch 100/100\n\u001b[1m77248/77248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.2957 - val_accuracy: 1.0000 - val_loss: 0.0018\n\n=== Classification Report ===\n              precision    recall  f1-score   support\n\n           0       0.89      0.68      0.77    386590\n           1       0.74      0.91      0.82    385888\n\n    accuracy                           0.80    772478\n   macro avg       0.82      0.80      0.80    772478\nweighted avg       0.82      0.80      0.80    772478\n\n[JSON] GAN result appended.\n✅ GAN Cell Completed (Tiny + JSON saved + Weights saved)\n","output_type":"stream"}],"execution_count":6}]}